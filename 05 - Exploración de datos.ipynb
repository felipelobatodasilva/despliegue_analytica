{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_order_reviews_dataset.parquet\n",
      "Tamaño del DataFrame: (104162, 7)\n",
      "Columnas del DataFrame: ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/product_category_name_translation.parquet\n",
      "Tamaño del DataFrame: (71, 2)\n",
      "Columnas del DataFrame: ['product_category_name', 'product_category_name_english']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/log.parquet\n",
      "Tamaño del DataFrame: (1312162, 13)\n",
      "Columnas del DataFrame: ['cep_id', 'cep', 'tipo', 'nome_logradouro', 'logradouro', 'bairro_id', 'cidade_id', 'estado', 'complemento', 'latitude', 'longitude', 'cep_ativo', 'cep_ibge']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_order_payments_dataset.parquet\n",
      "Tamaño del DataFrame: (103886, 5)\n",
      "Columnas del DataFrame: ['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_order_items_dataset.parquet\n",
      "Tamaño del DataFrame: (112650, 7)\n",
      "Columnas del DataFrame: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_customers_dataset.parquet\n",
      "Tamaño del DataFrame: (99441, 5)\n",
      "Columnas del DataFrame: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/geo_coords.parquet\n",
      "Tamaño del DataFrame: (19988, 3)\n",
      "Columnas del DataFrame: ['cep_prefix', 'lat', 'lon']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_products_dataset.parquet\n",
      "Tamaño del DataFrame: (32951, 9)\n",
      "Columnas del DataFrame: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_sellers_dataset.parquet\n",
      "Tamaño del DataFrame: (3095, 4)\n",
      "Columnas del DataFrame: ['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_geolocation_dataset.parquet\n",
      "Tamaño del DataFrame: (1000163, 5)\n",
      "Columnas del DataFrame: ['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng', 'geolocation_city', 'geolocation_state']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/geolocation_correios.parquet\n",
      "Tamaño del DataFrame: (83930384, 4)\n",
      "Columnas del DataFrame: ['cep', 'city', 'uf', 'cep_prefix']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_orders_dataset.parquet\n",
      "Tamaño del DataFrame: (99441, 8)\n",
      "Columnas del DataFrame: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Función para explorar el tamaño de la base de datos y enlistar columnas\n",
    "def explorar_dataframe(archivo):\n",
    "    df = pd.read_parquet(archivo)  # Cargar el archivo parquet\n",
    "    print(f\"Explorando el archivo: {archivo}\")\n",
    "    print(f\"Tamaño del DataFrame: {df.shape}\")  # Muestra el tamaño (filas, columnas)\n",
    "    print(\"Columnas del DataFrame:\", df.columns.tolist())  # Lista de nombres de columnas\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Ruta de la carpeta donde se encuentran los archivos parquet\n",
    "folder_path = '/home/nicolas/despliegue_analytica/files_parquet/'\n",
    "\n",
    "# Listar archivos parquet en el directorio\n",
    "archivos_en_directorio = os.listdir(folder_path)\n",
    "\n",
    "# Filtrar solo los archivos parquet\n",
    "archivos_parquet = [archivo for archivo in archivos_en_directorio if archivo.endswith('.parquet')]\n",
    "\n",
    "# Explorar cada archivo\n",
    "for archivo in archivos_parquet:\n",
    "    explorar_dataframe(os.path.join(folder_path, archivo))  # Combina la ruta de la carpeta con el nombre del archivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_order_reviews_dataset.parquet\n",
      "Tamaño del DataFrame: (104162, 7)\n",
      "Columnas del DataFrame: ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "Posibles llaves para JOIN: ['order_id']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/product_category_name_translation.parquet\n",
      "Tamaño del DataFrame: (71, 2)\n",
      "Columnas del DataFrame: ['product_category_name', 'product_category_name_english']\n",
      "No se encontraron posibles llaves para JOIN.\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/log.parquet\n",
      "Tamaño del DataFrame: (1312162, 13)\n",
      "Columnas del DataFrame: ['cep_id', 'cep', 'tipo', 'nome_logradouro', 'logradouro', 'bairro_id', 'cidade_id', 'estado', 'complemento', 'latitude', 'longitude', 'cep_ativo', 'cep_ibge']\n",
      "Posibles llaves para JOIN: ['cep']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_order_payments_dataset.parquet\n",
      "Tamaño del DataFrame: (103886, 5)\n",
      "Columnas del DataFrame: ['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']\n",
      "Posibles llaves para JOIN: ['order_id']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_order_items_dataset.parquet\n",
      "Tamaño del DataFrame: (112650, 7)\n",
      "Columnas del DataFrame: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "Posibles llaves para JOIN: ['order_id', 'product_id', 'seller_id']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_customers_dataset.parquet\n",
      "Tamaño del DataFrame: (99441, 5)\n",
      "Columnas del DataFrame: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "Posibles llaves para JOIN: ['customer_id']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/geo_coords.parquet\n",
      "Tamaño del DataFrame: (19988, 3)\n",
      "Columnas del DataFrame: ['cep_prefix', 'lat', 'lon']\n",
      "Posibles llaves para JOIN: ['cep_prefix']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_products_dataset.parquet\n",
      "Tamaño del DataFrame: (32951, 9)\n",
      "Columnas del DataFrame: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "Posibles llaves para JOIN: ['product_id']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_sellers_dataset.parquet\n",
      "Tamaño del DataFrame: (3095, 4)\n",
      "Columnas del DataFrame: ['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state']\n",
      "Posibles llaves para JOIN: ['seller_id']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_geolocation_dataset.parquet\n",
      "Tamaño del DataFrame: (1000163, 5)\n",
      "Columnas del DataFrame: ['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng', 'geolocation_city', 'geolocation_state']\n",
      "No se encontraron posibles llaves para JOIN.\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/geolocation_correios.parquet\n",
      "Tamaño del DataFrame: (83930384, 4)\n",
      "Columnas del DataFrame: ['cep', 'city', 'uf', 'cep_prefix']\n",
      "Posibles llaves para JOIN: ['cep', 'cep_prefix']\n",
      "\n",
      "\n",
      "Explorando el archivo: /home/nicolas/despliegue_analytica/files_parquet/olist_orders_dataset.parquet\n",
      "Tamaño del DataFrame: (99441, 8)\n",
      "Columnas del DataFrame: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "Posibles llaves para JOIN: ['order_id', 'customer_id']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de posibles columnas clave para joins (identificadores comunes)\n",
    "posibles_llaves = ['order_id', 'customer_id', 'product_id', 'seller_id', 'cep', 'cep_prefix']\n",
    "\n",
    "# Función para explorar el tamaño de la base de datos y enlistar columnas, indicando posibles llaves para join\n",
    "def explorar_dataframe(archivo):\n",
    "    df = pd.read_parquet(archivo)  # Cargar el archivo parquet\n",
    "    columnas = df.columns.tolist()  # Lista de columnas\n",
    "    llaves_encontradas = [col for col in columnas if col in posibles_llaves]  # Identificar llaves para join\n",
    "    \n",
    "    print(f\"Explorando el archivo: {archivo}\")\n",
    "    print(f\"Tamaño del DataFrame: {df.shape}\")  # Muestra el tamaño (filas, columnas)\n",
    "    print(\"Columnas del DataFrame:\", columnas)  # Lista de nombres de columnas\n",
    "    \n",
    "    if llaves_encontradas:\n",
    "        print(f\"Posibles llaves para JOIN: {llaves_encontradas}\")  # Muestra llaves si se encuentran\n",
    "    else:\n",
    "        print(\"No se encontraron posibles llaves para JOIN.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Ruta de la carpeta donde se encuentran los archivos parquet\n",
    "folder_path = '/home/nicolas/despliegue_analytica/files_parquet/'\n",
    "\n",
    "# Listar archivos parquet en el directorio\n",
    "archivos_en_directorio = os.listdir(folder_path)\n",
    "\n",
    "# Filtrar solo los archivos parquet\n",
    "archivos_parquet = [archivo for archivo in archivos_en_directorio if archivo.endswith('.parquet')]\n",
    "\n",
    "# Explorar cada archivo\n",
    "for archivo in archivos_parquet:\n",
    "    explorar_dataframe(os.path.join(folder_path, archivo))  # Combina la ruta de la carpeta con el nombre del archivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join completo y archivo guardado en: /home/nicolas/despliegue_analytica/files_parquet/olist_dataset_combinado.parquet\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Ruta de la carpeta donde se encuentran los archivos parquet\n",
    "folder_path = '/home/nicolas/despliegue_analytica/files_parquet/'\n",
    "\n",
    "# Cargar los archivos parquet como Dask DataFrames\n",
    "df_order_reviews = dd.read_parquet(folder_path + 'olist_order_reviews_dataset.parquet')\n",
    "df_payments = dd.read_parquet(folder_path + 'olist_order_payments_dataset.parquet')\n",
    "df_order_items = dd.read_parquet(folder_path + 'olist_order_items_dataset.parquet')\n",
    "df_customers = dd.read_parquet(folder_path + 'olist_customers_dataset.parquet')\n",
    "df_products = dd.read_parquet(folder_path + 'olist_products_dataset.parquet')\n",
    "df_sellers = dd.read_parquet(folder_path + 'olist_sellers_dataset.parquet')\n",
    "df_orders = dd.read_parquet(folder_path + 'olist_orders_dataset.parquet')\n",
    "df_log = dd.read_parquet(folder_path + 'log.parquet')\n",
    "\n",
    "# Convertir las columnas a string donde sea necesario\n",
    "df_log['cep'] = df_log['cep'].astype(str)\n",
    "\n",
    "# Realizar los joins progresivamente usando Dask\n",
    "# 1. Unir orders con customers por 'customer_id'\n",
    "df = dd.merge(df_orders, df_customers, on='customer_id', how='left')\n",
    "\n",
    "# 2. Unir order_reviews con orders por 'order_id'\n",
    "df = dd.merge(df, df_order_reviews, on='order_id', how='left')\n",
    "\n",
    "# 3. Unir payments con orders por 'order_id'\n",
    "df = dd.merge(df, df_payments, on='order_id', how='left')\n",
    "\n",
    "# 4. Unir order_items con orders por 'order_id'\n",
    "df = dd.merge(df, df_order_items, on='order_id', how='left')\n",
    "\n",
    "# 5. Unir products con order_items por 'product_id'\n",
    "df = dd.merge(df, df_products, on='product_id', how='left')\n",
    "\n",
    "# 6. Unir sellers con order_items por 'seller_id'\n",
    "df = dd.merge(df, df_sellers, on='seller_id', how='left')\n",
    "\n",
    "# 7. Unir log (llave: cep) con el DataFrame resultante\n",
    "df = dd.merge(df, df_log[['cep', 'logradouro', 'bairro_id', 'cidade_id', 'estado']], \n",
    "              left_on='customer_zip_code_prefix', right_on='cep', how='left')\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo parquet\n",
    "output_path = '/home/nicolas/despliegue_analytica/files_parquet/olist_dataset_combinado.parquet'\n",
    "df.to_parquet(output_path, write_index=False)\n",
    "\n",
    "print(\"Join completo y archivo guardado en:\", output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas: 119143\n",
      "Número de columnas: 44\n",
      "Estadísticas descriptivas:\n",
      "             order_purchase_timestamp           order_approved_at  \\\n",
      "count                         119143                      118966   \n",
      "min              2016-09-05 00:15:19         2016-09-15 15:16:38   \n",
      "25%    2017-09-17 20:05:23.750000128  2017-09-19 02:41:29.500000   \n",
      "50%              2018-01-24 23:06:24         2018-01-25 11:05:25   \n",
      "75%              2018-05-07 23:48:25         2018-05-08 07:49:49   \n",
      "max              2018-10-17 20:30:18         2018-09-03 20:40:06   \n",
      "mean                            <NA>                        <NA>   \n",
      "std                             <NA>                        <NA>   \n",
      "\n",
      "      order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "count                       117057                        115722   \n",
      "min            2016-10-08 13:34:01           2016-10-11 16:46:32   \n",
      "25%            2017-09-21 22:17:58           2017-10-03 21:53:05   \n",
      "50%            2018-01-29 23:52:38           2018-02-09 22:03:59   \n",
      "75%            2018-05-09 19:32:00           2018-05-17 18:52:09   \n",
      "max            2018-09-11 22:48:28           2018-10-17 16:22:46   \n",
      "mean                          <NA>                          <NA>   \n",
      "std                           <NA>                          <NA>   \n",
      "\n",
      "      order_estimated_delivery_date  payment_sequential  payment_installments  \\\n",
      "count                        119143       119140.000000         119140.000000   \n",
      "min             2016-09-30 03:00:00            1.000000              0.000000   \n",
      "25%             2017-10-10 03:00:00            1.000000              1.000000   \n",
      "50%             2018-02-20 03:00:00            1.000000              2.000000   \n",
      "75%             2018-05-29 03:00:00            1.000000              4.000000   \n",
      "max             2018-11-12 02:00:00           29.000000             24.000000   \n",
      "mean                           <NA>            1.094737              2.941246   \n",
      "std                            <NA>            0.730141              2.777848   \n",
      "\n",
      "       payment_value  order_item_id            shipping_limit_date  ...  \\\n",
      "count  119140.000000  118310.000000                         118310  ...   \n",
      "min         0.000000       1.000000            2016-09-19 03:15:34  ...   \n",
      "25%        62.195000       1.000000  2017-09-26 00:32:23.750000128  ...   \n",
      "50%       111.030000       1.000000            2018-02-01 04:52:27  ...   \n",
      "75%       197.132500       1.000000            2018-05-14 07:15:36  ...   \n",
      "max     13664.080000      21.000000            2020-04-10 01:35:08  ...   \n",
      "mean      172.735135       1.196543                           <NA>  ...   \n",
      "std       267.776077       0.699489                           <NA>  ...   \n",
      "\n",
      "       freight_value  product_name_lenght  product_description_lenght  \\\n",
      "count  118310.000000        116601.000000               116601.000000   \n",
      "min         0.000000             5.000000                    4.000000   \n",
      "25%        13.440000            43.000000                  351.000000   \n",
      "50%        16.710000            52.000000                  614.000000   \n",
      "75%        21.680000            57.000000                 1025.000000   \n",
      "max       409.680000            76.000000                 3992.000000   \n",
      "mean       20.032387            48.767498                  785.967822   \n",
      "std        15.836850            10.033540                  652.584121   \n",
      "\n",
      "       product_photos_qty  product_weight_g  product_length_cm  \\\n",
      "count       116601.000000     118290.000000      118290.000000   \n",
      "min              1.000000          0.000000           7.000000   \n",
      "25%              1.000000        300.000000          19.000000   \n",
      "50%              2.000000        700.000000          25.000000   \n",
      "75%              3.000000       1900.000000          39.000000   \n",
      "max             20.000000      40425.000000         105.000000   \n",
      "mean             2.205161       2112.250740          30.265145   \n",
      "std              1.717452       3786.695111          16.189367   \n",
      "\n",
      "       product_height_cm  product_width_cm  bairro_id  cidade_id  \n",
      "count      118290.000000     118290.000000        0.0        0.0  \n",
      "min             2.000000          6.000000        NaN        NaN  \n",
      "25%             8.000000         15.000000        NaN        NaN  \n",
      "50%            13.000000         20.000000        NaN        NaN  \n",
      "75%            21.000000         30.000000        NaN        NaN  \n",
      "max           105.000000        118.000000        NaN        NaN  \n",
      "mean           16.619706         23.074799        NaN        NaN  \n",
      "std            13.453584         11.749139        NaN        NaN  \n",
      "\n",
      "[8 rows x 21 columns]\n",
      "Primeras filas del DataFrame:\n",
      "                            order_id                       customer_id  \\\n",
      "0  bb8f873e2d4e898546ba92f7febc7b34  50b8c8be62013d9544bb456ade24e2dd   \n",
      "1  2e3400d43bbd1c921a404c654a0e7bf7  e6c5cb7ce7b3053a70e5d43981faed19   \n",
      "2  0d8e03520c1b877edaf5ef24f7abb5cb  00205ad9ba1ef4340cef86583294cf82   \n",
      "3  30d9b6778c881209fbbe2d1fdc6b3aa7  c46fb1ad081f67129badf67837c1727c   \n",
      "4  c2aa930596277db8a490948feb446df4  6c769db0ae5e4b009eea220b38948f7e   \n",
      "\n",
      "  order_status order_purchase_timestamp   order_approved_at  \\\n",
      "0    delivered      2018-06-18 14:33:07 2018-06-20 05:55:39   \n",
      "1    delivered      2017-07-29 00:30:19 2017-07-29 00:45:09   \n",
      "2    delivered      2018-05-12 20:51:47 2018-05-13 15:15:10   \n",
      "3    delivered      2017-12-01 00:56:51 2017-12-01 12:30:54   \n",
      "4    delivered      2017-09-11 21:09:30 2017-09-11 21:24:01   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2018-06-20 23:11:00           2018-06-21 20:58:28   \n",
      "1          2017-08-01 17:22:41           2017-08-09 01:14:46   \n",
      "2          2018-05-18 18:17:00           2018-06-11 17:03:50   \n",
      "3          2017-12-06 02:58:48           2017-12-14 15:47:06   \n",
      "4          2017-09-14 23:27:55           2017-09-25 21:08:08   \n",
      "\n",
      "  order_estimated_delivery_date                customer_unique_id  \\\n",
      "0           2018-07-05 03:00:00  707e3ae26b58fcee0b10ef1185c1ec39   \n",
      "1           2017-08-23 03:00:00  e665b6116800e2c6a72535bb53dae6ca   \n",
      "2           2018-06-26 03:00:00  28a4a9aa9bd3640e1f9a9cf542cb25fd   \n",
      "3           2017-12-19 02:00:00  de2ca7b13e8e419507948976ca8df56c   \n",
      "4           2017-10-02 03:00:00  c0802c5a5546df8fb79ee70975f17929   \n",
      "\n",
      "  customer_zip_code_prefix  ... product_height_cm product_width_cm  \\\n",
      "0                    04807  ...              14.0             19.0   \n",
      "1                    31230  ...               9.0             14.0   \n",
      "2                    58090  ...              35.0             50.0   \n",
      "3                    05794  ...              40.0             30.0   \n",
      "4                    26950  ...              10.0             18.0   \n",
      "\n",
      "  seller_zip_code_prefix seller_city seller_state   cep logradouro bairro_id  \\\n",
      "0                  09920     diadema           SP  <NA>       <NA>       NaN   \n",
      "1                  87050     maringa           PR  <NA>       <NA>       NaN   \n",
      "2                  03029   sao paulo           SP  <NA>       <NA>       NaN   \n",
      "3                  13481     limeira           SP  <NA>       <NA>       NaN   \n",
      "4                  06440     barueri           SP  <NA>       <NA>       NaN   \n",
      "\n",
      "   cidade_id estado  \n",
      "0        NaN   <NA>  \n",
      "1        NaN   <NA>  \n",
      "2        NaN   <NA>  \n",
      "3        NaN   <NA>  \n",
      "4        NaN   <NA>  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "Conteo de valores nulos por columna:\n",
      " order_id                              0\n",
      "customer_id                           0\n",
      "order_status                          0\n",
      "order_purchase_timestamp              0\n",
      "order_approved_at                   177\n",
      "order_delivered_carrier_date       2086\n",
      "order_delivered_customer_date      3421\n",
      "order_estimated_delivery_date         0\n",
      "customer_unique_id                    0\n",
      "customer_zip_code_prefix              0\n",
      "customer_city                         0\n",
      "customer_state                        0\n",
      "review_id                           997\n",
      "review_score                        997\n",
      "review_comment_title             105154\n",
      "review_comment_message            68898\n",
      "review_creation_date               5864\n",
      "review_answer_timestamp            5866\n",
      "payment_sequential                    3\n",
      "payment_type                          3\n",
      "payment_installments                  3\n",
      "payment_value                         3\n",
      "order_item_id                       833\n",
      "product_id                          833\n",
      "seller_id                           833\n",
      "shipping_limit_date                 833\n",
      "price                               833\n",
      "freight_value                       833\n",
      "product_category_name              2542\n",
      "product_name_lenght                2542\n",
      "product_description_lenght         2542\n",
      "product_photos_qty                 2542\n",
      "product_weight_g                    853\n",
      "product_length_cm                   853\n",
      "product_height_cm                   853\n",
      "product_width_cm                    853\n",
      "seller_zip_code_prefix              833\n",
      "seller_city                         833\n",
      "seller_state                        833\n",
      "cep                              119143\n",
      "logradouro                       119143\n",
      "bairro_id                        119143\n",
      "cidade_id                        119143\n",
      "estado                           119143\n",
      "dtype: int64\n",
      "Tipos de variables:\n",
      " order_id                         string[pyarrow]\n",
      "customer_id                      string[pyarrow]\n",
      "order_status                     string[pyarrow]\n",
      "order_purchase_timestamp          datetime64[ns]\n",
      "order_approved_at                 datetime64[ns]\n",
      "order_delivered_carrier_date      datetime64[ns]\n",
      "order_delivered_customer_date     datetime64[ns]\n",
      "order_estimated_delivery_date     datetime64[ns]\n",
      "customer_unique_id               string[pyarrow]\n",
      "customer_zip_code_prefix         string[pyarrow]\n",
      "customer_city                    string[pyarrow]\n",
      "customer_state                   string[pyarrow]\n",
      "review_id                        string[pyarrow]\n",
      "review_score                     string[pyarrow]\n",
      "review_comment_title             string[pyarrow]\n",
      "review_comment_message           string[pyarrow]\n",
      "review_creation_date             string[pyarrow]\n",
      "review_answer_timestamp          string[pyarrow]\n",
      "payment_sequential                         int32\n",
      "payment_type                     string[pyarrow]\n",
      "payment_installments                       int32\n",
      "payment_value                            float64\n",
      "order_item_id                              int32\n",
      "product_id                       string[pyarrow]\n",
      "seller_id                        string[pyarrow]\n",
      "shipping_limit_date               datetime64[ns]\n",
      "price                                    float64\n",
      "freight_value                            float64\n",
      "product_category_name            string[pyarrow]\n",
      "product_name_lenght                        int32\n",
      "product_description_lenght                 int32\n",
      "product_photos_qty                         int32\n",
      "product_weight_g                           int32\n",
      "product_length_cm                          int32\n",
      "product_height_cm                          int32\n",
      "product_width_cm                           int32\n",
      "seller_zip_code_prefix           string[pyarrow]\n",
      "seller_city                      string[pyarrow]\n",
      "seller_state                     string[pyarrow]\n",
      "cep                              string[pyarrow]\n",
      "logradouro                       string[pyarrow]\n",
      "bairro_id                                  int32\n",
      "cidade_id                                  int32\n",
      "estado                           string[pyarrow]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Cargar el archivo parquet como Dask DataFrame\n",
    "folder_path = '/home/nicolas/despliegue_analytica/files_parquet/'\n",
    "df_combined = dd.read_parquet(folder_path + 'olist_dataset_combinado.parquet')\n",
    "\n",
    "# Tamaño del DataFrame\n",
    "num_rows, num_cols = df_combined.shape\n",
    "print(\"Número de filas:\", num_rows.compute())  # Computa el número de filas\n",
    "print(\"Número de columnas:\", num_cols)  # Ya es un entero\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "stats = df_combined.describe()\n",
    "print(\"Estadísticas descriptivas:\\n\", stats.compute())  # Computa las estadísticas y las muestra\n",
    "\n",
    "# Para ver las primeras filas del DataFrame\n",
    "print(\"Primeras filas del DataFrame:\\n\", df_combined.head())  # Muestra las primeras filas\n",
    "\n",
    "# Conteo de valores nulos por columna\n",
    "null_counts = df_combined.isnull().sum().compute()\n",
    "print(\"Conteo de valores nulos por columna:\\n\", null_counts)\n",
    "\n",
    "# Tipos de variables\n",
    "dtypes = df_combined.dtypes  # Obtiene los tipos de variables\n",
    "print(\"Tipos de variables:\\n\", dtypes)  # Muestra los tipos de variables (no necesita compute)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
