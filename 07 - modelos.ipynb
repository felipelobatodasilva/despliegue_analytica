{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "df[['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente',\"id_producto\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Cargar la base de datos\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "\n",
    "# Selección de características relevantes para la predicción\n",
    "features = ['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "target = 'precio'\n",
    "\n",
    "# Preparar datos\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numerical_features = ['peso_producto_g', 'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm']\n",
    "categorical_features = ['temporada', 'nombre_categoria_producto', 'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "\n",
    "# Transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Construcción del modelo con pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir parámetros para la búsqueda de hiperparámetros con GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__max_depth': [3, 6, 9],\n",
    "    'regressor__subsample': [0.7, 0.8, 0.9],\n",
    "    'regressor__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'regressor__gamma': [0, 0.1, 0.2],\n",
    "    'regressor__reg_alpha': [0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Entrenamiento del modelo con GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo y sus parámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Predicción con el mejor modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Calcular R² (Coeficiente de Determinación)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Evaluación con validación cruzada\n",
    "cross_val_rmse = np.sqrt(-cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Cargar la base de datos\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "\n",
    "# Selección de características relevantes para la predicción\n",
    "features = ['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "target = 'precio'\n",
    "\n",
    "# Preparar datos\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numerical_features = ['peso_producto_g', 'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm']\n",
    "categorical_features = ['temporada', 'nombre_categoria_producto', 'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "\n",
    "# Transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Construcción del modelo con pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir parámetros para la búsqueda de hiperparámetros con RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['sqrt', 'log2'],  \n",
    "    'regressor__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, verbose=2, random_state=42,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo con RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo y sus parámetros\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "# Predicción con el mejor modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Calcular MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Calcular R² (Coeficiente de Determinación)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Evaluación con validación cruzada\n",
    "cross_val_rmse = np.sqrt(-cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n",
    "\n",
    "# Ejemplo de predicción para un nuevo dato\n",
    "new_data = pd.DataFrame({\n",
    "    'temporada': ['Invierno'],\n",
    "    'nombre_categoria_producto': ['cama_mesa_banho'],\n",
    "    'id_producto': ['364e789259da982f5b7e43aaea7be61'],\n",
    "    'peso_producto_g': [750],\n",
    "    'largo_producto_cm': [16],\n",
    "    'altura_producto_cm': [10],\n",
    "    'ancho_producto_cm': [16],\n",
    "    'ciudad_cliente': ['sao_paulo'],\n",
    "    'estado_cliente': ['SP']\n",
    "})\n",
    "predicted_price = best_model.predict(new_data)\n",
    "print(f\"Predicted Seasonal Price: {predicted_price[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Cargar la base de datos\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "\n",
    "# Selección de características relevantes para la predicción\n",
    "features = ['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "target = 'precio'\n",
    "\n",
    "# Preparar datos\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numerical_features = ['peso_producto_g', 'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm']\n",
    "categorical_features = ['temporada', 'nombre_categoria_producto', 'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "\n",
    "# Transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ \n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Construcción del modelo con pipeline usando regresión lineal\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción con el modelo entrenado\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Calcular MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Calcular R² (Coeficiente de Determinación)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Evaluación con validación cruzada\n",
    "cross_val_rmse = np.sqrt(-cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n",
    "\n",
    "# Ejemplo de predicción para un nuevo dato\n",
    "new_data = pd.DataFrame({\n",
    "    'temporada': ['Invierno'],\n",
    "    'nombre_categoria_producto': ['cama_mesa_banho'],\n",
    "    'id_producto': ['364e789259da982f5b7e43aaea7be61'],\n",
    "    'peso_producto_g': [750],\n",
    "    'largo_producto_cm': [16],\n",
    "    'altura_producto_cm': [10],\n",
    "    'ancho_producto_cm': [16],\n",
    "    'ciudad_cliente': ['sao_paulo'],\n",
    "    'estado_cliente': ['SP']\n",
    "})\n",
    "predicted_price = model.predict(new_data)\n",
    "print(f\"Predicted Seasonal Price: {predicted_price[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Cargar la base de datos\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "\n",
    "# Selección de características relevantes para la predicción\n",
    "features = ['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "target = 'precio'\n",
    "\n",
    "# Preparar datos\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numerical_features = ['peso_producto_g', 'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm']\n",
    "categorical_features = ['temporada', 'nombre_categoria_producto', 'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "\n",
    "# Transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ \n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Construcción del modelo con pipeline usando ElasticNet\n",
    "model = Pipeline(steps=[ \n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', ElasticNet())\n",
    "])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción con el modelo entrenado\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Calcular MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Calcular R² (Coeficiente de Determinación)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Evaluación con validación cruzada\n",
    "cross_val_rmse = np.sqrt(-cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n",
    "\n",
    "# Ejemplo de predicción para un nuevo dato\n",
    "new_data = pd.DataFrame({\n",
    "    'temporada': ['Invierno'],\n",
    "    'nombre_categoria_producto': ['cama_mesa_banho'],\n",
    "    'id_producto': ['364e789259da982f5b7e43aaea7be61'],\n",
    "    'peso_producto_g': [750],\n",
    "    'largo_producto_cm': [16],\n",
    "    'altura_producto_cm': [10],\n",
    "    'ancho_producto_cm': [16],\n",
    "    'ciudad_cliente': ['sao_paulo'],\n",
    "    'estado_cliente': ['SP']\n",
    "})\n",
    "predicted_price = model.predict(new_data)\n",
    "print(f\"Predicted Seasonal Price: {predicted_price[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Cargar la base de datos\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "\n",
    "# Selección de características relevantes para la predicción\n",
    "features = ['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "target = 'precio'\n",
    "\n",
    "# Preparar datos\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numerical_features = ['peso_producto_g', 'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm']\n",
    "categorical_features = ['temporada', 'nombre_categoria_producto', 'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "\n",
    "# Transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ \n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Construcción del modelo con pipeline usando K-Nearest Neighbors\n",
    "model = Pipeline(steps=[ \n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajuste de hiperparámetros con GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_neighbors': [3, 5, 7, 10],  # Número de vecinos\n",
    "    'regressor__weights': ['uniform', 'distance'],  # Cómo ponderar los vecinos\n",
    "    'regressor__p': [1, 2]  # Normas para la distancia (1=Manhattan, 2=Euclidiana)\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Predicción con el modelo ajustado\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calcular MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular RMSE (Root Mean Squared Error)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Calcular MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Calcular R² (Coeficiente de Determinación)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2}\")\n",
    "\n",
    "# Evaluación con validación cruzada\n",
    "cross_val_rmse = np.sqrt(-cross_val_score(grid_search.best_estimator_, X, y, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "print(f\"Cross-validated RMSE: {cross_val_rmse}\")\n",
    "\n",
    "# Ejemplo de predicción para un nuevo dato\n",
    "new_data = pd.DataFrame({\n",
    "    'temporada': ['Invierno'],\n",
    "    'nombre_categoria_producto': ['cama_mesa_banho'],\n",
    "    'id_producto': ['364e789259da982f5b7e43aaea7be61'],\n",
    "    'peso_producto_g': [750],\n",
    "    'largo_producto_cm': [16],\n",
    "    'altura_producto_cm': [10],\n",
    "    'ancho_producto_cm': [16],\n",
    "    'ciudad_cliente': ['sao_paulo'],\n",
    "    'estado_cliente': ['SP']\n",
    "})\n",
    "predicted_price = grid_search.best_estimator_.predict(new_data)\n",
    "print(f\"Predicted Seasonal Price: {predicted_price[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparando modelos\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nombres de los modelos\n",
    "model_names = [\n",
    "    \"XGBRegressor\", \n",
    "    \"RandomForestRegressor\", \n",
    "    \"LinearRegression\", \n",
    "    \"ElasticNet\", \n",
    "    \"KNeighborsRegressor\"\n",
    "]\n",
    "\n",
    "# Métricas de cada modelo\n",
    "rmse_scores = [\n",
    "    132.67,  # XGBRegressor\n",
    "    135.53,  # RandomForestRegressor\n",
    "    118.01,  # LinearRegression\n",
    "    183.53,    # ElasticNet\n",
    "    142.54   # KNeighborsRegressor\n",
    "]\n",
    "\n",
    "mae_scores = [\n",
    "    54.76,   # XGBRegressor\n",
    "    43.09,   # RandomForestRegressor\n",
    "    25.55,   # LinearRegression\n",
    "    81.10,     # ElasticNet\n",
    "    39.61    # KNeighborsRegressor\n",
    "]\n",
    "\n",
    "r2_scores = [\n",
    "    0.54,    # XGBRegressor\n",
    "    0.52,    # RandomForestRegressor\n",
    "    0.63,    # LinearRegression\n",
    "    0.11,      # ElasticNet\n",
    "    0.47     # KNeighborsRegressor\n",
    "]\n",
    "\n",
    "# Ordenar las métricas y modelos de mayor a menor\n",
    "rmse_order = np.argsort(rmse_scores)[::-1]\n",
    "mae_order = np.argsort(mae_scores)[::-1]\n",
    "r2_order = np.argsort(r2_scores)[::-1]\n",
    "\n",
    "# Aplicar el orden a cada lista\n",
    "rmse_scores_sorted = [rmse_scores[i] for i in rmse_order]\n",
    "mae_scores_sorted = [mae_scores[i] for i in mae_order]\n",
    "r2_scores_sorted = [r2_scores[i] for i in r2_order]\n",
    "\n",
    "model_names_rmse_sorted = [model_names[i] for i in rmse_order]\n",
    "model_names_mae_sorted = [model_names[i] for i in mae_order]\n",
    "model_names_r2_sorted = [model_names[i] for i in r2_order]\n",
    "\n",
    "# Crear subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Comparación de Modelos (Ordenados de Mayor a Menor)')\n",
    "\n",
    "# Gráfico RMSE\n",
    "axes[0].bar(model_names_rmse_sorted, rmse_scores_sorted, color='skyblue')\n",
    "axes[0].set_title('RMSE')\n",
    "axes[0].set_ylabel('Root Mean Squared Error')\n",
    "axes[0].set_xticklabels(model_names_rmse_sorted, rotation=45)\n",
    "\n",
    "# Gráfico MAE\n",
    "axes[1].bar(model_names_mae_sorted, mae_scores_sorted, color='lightgreen')\n",
    "axes[1].set_title('MAE')\n",
    "axes[1].set_ylabel('Mean Absolute Error')\n",
    "axes[1].set_xticklabels(model_names_mae_sorted, rotation=45)\n",
    "\n",
    "# Gráfico R²\n",
    "axes[2].bar(model_names_r2_sorted, r2_scores_sorted, color='salmon')\n",
    "axes[2].set_title('R²')\n",
    "axes[2].set_ylabel('Coeficiente de Determinación')\n",
    "axes[2].set_xticklabels(model_names_r2_sorted, rotation=45)\n",
    "\n",
    "# Mostrar los gráficos\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression es claramente el mejor modelo según estas métricas. Tiene los valores de RMSE y MAE más bajos y el valor de R² más alto, lo cual indica que es el modelo más preciso y confiable para este conjunto de datos. Por otro lado, ElasticNet es el menos efectivo, mostrando el peor rendimiento en todas las métricas. Si deseas una alternativa a LinearRegression, XGBRegressor podría ser una opción viable, aunque su rendimiento es inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo base_dash.csv guardado exitosamente con las predicciones incluidas.\n"
     ]
    }
   ],
   "source": [
    "#Prediccion y sacando la base prueba para el dash\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Cargar la base de datos\n",
    "df = pd.read_parquet('files_parquet/df_baseFinal.parquet', engine='pyarrow')\n",
    "\n",
    "# Selección de características relevantes para la predicción\n",
    "features = ['temporada', 'nombre_categoria_producto', 'peso_producto_g', \n",
    "            'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm', \n",
    "            'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "target = 'precio'\n",
    "\n",
    "# Preparar datos\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "numerical_features = ['peso_producto_g', 'largo_producto_cm', 'altura_producto_cm', 'ancho_producto_cm']\n",
    "categorical_features = ['temporada', 'nombre_categoria_producto', 'ciudad_cliente', 'estado_cliente', \"id_producto\"]\n",
    "\n",
    "# Transformaciones\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ \n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Construcción del modelo con pipeline usando regresión lineal\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción con el modelo entrenado en el conjunto completo de datos\n",
    "df['predicted_price'] = model.predict(X)\n",
    "\n",
    "# Guardar el DataFrame con la columna de predicción añadida\n",
    "df.to_csv('files_csv/base_dash.csv')\n",
    "print(\"Archivo base_dash.csv guardado exitosamente con las predicciones incluidas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
